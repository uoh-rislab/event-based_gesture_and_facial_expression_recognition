<!-- PROJECT LOGO -->
<br />
<p align="center">
  <a href="https://sites.google.com/uoh.cl/uoh-ris-lab">
    <img src="resources/uoh_ici.jpeg" alt="Logo" width="80" height="80">
  </a>

  <h3 align="center">Event-based Gesture and Facial Expression Recognition: A Comparative Analysis</h3>

  <p align="center">
     Codes for "Event-based Gesture and Facial Expression Recognition: A Comparative Analysis" 
    <br />
    <a href="https://sites.google.com/uoh.cl/uoh-ris-lab"><strong>Explore our laboratory»</strong></a>
    <br />

  </p>
</p>

This repository contains instructions on evaluated/implemented event-based objects recognition methods for gesture and facial expression recognition task, as described in R. Verschae, [I. Bugueno-Cordova](https://github.com/ibugueno/) "Event-based Gesture and Facial Expression Recognition: A Comparative Analysis". The paper can be found [here](#)

If you cite this article in an academic context, we appreciate a citation to the paper below:

```bibtex
@ARTICLE{,
  author={},
  journal={IEEE Access}, 
  title={}, 
  year={2023},
  volume={},
  number={},
  pages={},
  doi={}
}
```

## Datasets

* IBM DVS Gesture 128: The dataset can be accessed through [the official website](https://research.ibm.com/interactive/dvsgesture/), associated to the paper _"A. Amir, et. al. "A Low Power, Fully Event-Based Gesture Recognition System," 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, 2017."_. We thank the authors for their contribution.

* NavGesture: The dataset can be accessed through [the official website](https://www.frontiersin.org/articles/10.3389/fnins.2020.00275/full), associated to the paper _"Maro J-M, et. al., (2020) Event-Based Gesture Recognition With Dynamic Background Suppression Using Smartphone Computational Capabilities. Front. Neurosci. 14:275."_. We thank the authors for their contribution.

* e-CK+: The novel and synthetic event-based facial expression recognition dataset emulated from the _"The Extended Cohn-Kanade Dataset (CK+)"_ can be requested and accessed through [this following website](#). We thank the original authors for their contribution.

* e-MMI: The novel and synthetic event-based facial expression recognition dataset emulated from the _"MMI Facial Expression Database"_ can be requested and accessed through [this following website](#). We thank the original authors for their contribution.

## Codes, Requirements & Installation

* EST: Code, requirements and installation instructions provided in [the authors repository](https://github.com/uzh-rpg/rpg_event_representation_learning), which corresponds to the implementation of the paper _"D. Gehrig, et. al., "End-to-End Learning of Representations for Asynchronous Event-Based Data," 2019 IEEE/CVF International Conference on Computer Vision (ICCV), Seoul, Korea (South), 2019, pp. 5632-5642."_

* Asynet: Code, requirements and installation instructions provided in [the authors repository](https://github.com/uzh-rpg/rpg_asynet), which corresponds to the implementation of the paper _"Messikommer, N., et. al., (2020). Event-Based Asynchronous Sparse Convolutional Networks. In: Vedaldi, A., Bischof, H., Brox, T., Frahm, JM. (eds) Computer Vision – ECCV 2020. ECCV 2020. Lecture Notes in Computer Science(), vol 12353. Springer, Cham."_

* ESTM: Code provided in this repository, specifically in the 'estm/' folder. Requirements and installation instructions are identical to EST.

## Technical Details

For more information, please see the ["Event-based Gesture and Facial Expression Recognition: A Comparative Analysis" website](#).