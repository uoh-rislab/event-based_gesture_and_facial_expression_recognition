# Event-based Gesture and Facial Expression Recognition: A Comparative Analysis

This repository contains instructions on evaluated/implemented event-based objects recognition methods for gesture and facial expression recognition task, as described in R. Verschae, [I. Bugueno-Cordova](https://github.com/ibugueno/) "Event-based Gesture and Facial Expression Recognition: A Comparative Analysis". The paper can be found [here](#)

If you cite this article in an academic context, we appreciate a citation to the paper below:

```bibtex
@ARTICLE{,
  author={},
  journal={IEEE Access}, 
  title={}, 
  year={2023},
  volume={},
  number={},
  pages={},
  doi={}
}
```

## Datasets

* IBM DVS Gesture 128: The dataset can be accessed through [the official website](https://research.ibm.com/interactive/dvsgesture/), associated to the paper "A. Amir, et. al. "A Low Power, Fully Event-Based Gesture Recognition System," 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, 2017.". We thank the authors for their contribution.

* NavGesture: The dataset can be accessed through [the official website](https://www.frontiersin.org/articles/10.3389/fnins.2020.00275/full), associated to the paper "Maro J-M, et. al., (2020) Event-Based Gesture Recognition With Dynamic Background Suppression Using Smartphone Computational Capabilities. Front. Neurosci. 14:275.". We thank the authors for their contribution.

* e-CK+: The novel and synthetic event-based facial expression recognition dataset emulated from the "The Extended Cohn-Kanade Dataset (CK+)" can be requested and accessed through [this following website](#). We thank the original authors for their contribution.

* e-MMI: The novel and synthetic event-based facial expression recognition dataset emulated from the "MMI Facial Expression Database" can be requested and accessed through [this following website](#). We thank the original authors for their contribution.

## Codes, Requirements & Installation

* EST: Code, requirements and installation instructions provided in [the authors repository](https://github.com/uzh-rpg/rpg_event_representation_learning), which corresponds to the implementation of the paper "D. Gehrig, et. al., "End-to-End Learning of Representations for Asynchronous Event-Based Data," 2019 IEEE/CVF International Conference on Computer Vision (ICCV), Seoul, Korea (South), 2019, pp. 5632-5642."

* Asynet: Code, requirements and installation instructions provided in [the authors repository](https://github.com/uzh-rpg/rpg_asynet), which corresponds to the implementation of the paper "Messikommer, N., et. al., (2020). Event-Based Asynchronous Sparse Convolutional Networks. In: Vedaldi, A., Bischof, H., Brox, T., Frahm, JM. (eds) Computer Vision â€“ ECCV 2020. ECCV 2020. Lecture Notes in Computer Science(), vol 12353. Springer, Cham."

* ESTM: Code provided in this repository, specifically in the 'estm/' folder. Requirements and installation instructions are identical to EST.

## Technical Details

For more information, please see the ["Event-based Gesture and Facial Expression Recognition: A Comparative Analysis" website](#).